{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOskQ5OFB7S1j8NZMdyoj67",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahad-jeza/my-first-nerural-network---Planar_data_classification_with_one_hidden_layer/blob/main/GAN_on_ckd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas scikit-learn tensorflow numpy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load dataset\n",
        "data_url = 'kidney_disease.csv'\n",
        "data = pd.read_csv(data_url)\n",
        "\n",
        "# Preprocess data\n",
        "label_encoder = LabelEncoder()\n",
        "for column in ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'classification']:\n",
        "    data[column] = label_encoder.fit_transform(data[column])\n",
        "\n",
        "# Handle missing values for numeric columns\n",
        "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
        "data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())\n",
        "\n",
        "# Handle missing values for categorical columns (if any)\n",
        "categorical_columns = data.select_dtypes(exclude=np.number).columns.tolist()\n",
        "data[categorical_columns] = data[categorical_columns].fillna(\"Unknown\")\n",
        "\n",
        "# Encode categorical variables\n",
        "data_encoded = pd.get_dummies(data, columns=categorical_columns)\n",
        "\n",
        "# Separate features and labels\n",
        "X = data_encoded.drop(columns=['id', 'classification'])\n",
        "y = data_encoded['classification']\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUbdfilpIymM",
        "outputId": "621591cd-f970-40b5-db05-580cbdffa02b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN model to balance the dataset\n",
        "latent_dim = 32\n",
        "\n",
        "def build_generator(latent_dim, n_outputs):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(128, activation='relu', input_dim=latent_dim))\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dense(n_outputs, activation='linear'))\n",
        "    return model\n",
        "\n",
        "def build_discriminator(n_inputs):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(512, activation='relu', input_dim=n_inputs))\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "generator = build_generator(latent_dim, X_train.shape[1])\n",
        "discriminator = build_discriminator(X_train.shape[1])\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = layers.Input(shape=(latent_dim,))\n",
        "generated_data = generator(gan_input)\n",
        "gan_output = discriminator(generated_data)\n",
        "gan = tf.keras.Model(gan_input, gan_output)\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    input = np.random.randn(latent_dim * n_samples)\n",
        "    input = input.reshape(n_samples, latent_dim)\n",
        "    X = generator.predict(input)\n",
        "    y = np.zeros((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "def generate_real_samples(n_samples):\n",
        "    idx = np.random.randint(0, X_train.shape[0], n_samples)\n",
        "    X = X_train[idx]\n",
        "    y = np.ones((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "def train_gan(gan, generator, discriminator, latent_dim, n_epochs=1000, n_batch=128):\n",
        "    half_batch = int(n_batch / 2)\n",
        "    for i in range(n_epochs):\n",
        "        X_real, y_real = generate_real_samples(half_batch)\n",
        "        X_fake, y_fake = generate_fake_samples(generator, latent_dim, half_batch)\n",
        "        discriminator.train_on_batch(X_real, y_real)\n",
        "        discriminator.train_on_batch(X_fake, y_fake)\n",
        "        X_gan = np.random.randn(latent_dim * n_batch)\n",
        "        X_gan = X_gan.reshape(n_batch, latent_dim)\n",
        "        y_gan = np.ones((n_batch, 1))\n",
        "        gan.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "train_gan(gan, generator, discriminator, latent_dim)\n",
        "\n",
        "n_samples = len(X_train) - sum(y_train == 0)\n",
        "X_fake, _ = generate_fake_samples(generator, latent_dim, n_samples)\n",
        "y_fake = np.ones((n_samples, ))\n",
        "\n",
        "X_balanced = np.vstack((X_train, X_fake))\n",
        "y_balanced = np.hstack((y_train, y_fake))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew80UhjhI3yt",
        "outputId": "8926ab89-9aa1-419d-904d-0d4800d7f09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "rf_accuracy = rf_model.score(X_test, y_test)\n",
        "print(f\"Random Forest Test Accuracy: {rf_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm_Gk7mJI8RN",
        "outputId": "bd3fd2e1-1c38-4cdc-a55c-c1cd076f94e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Test Accuracy: 97.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the balanced dataset\n",
        "rf_model.fit(X_balanced, y_balanced)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "rf_accuracy = rf_model.score(X_test, y_test)\n",
        "print(f\"Random Forest Test Accuracy on Balanced Dataset: {rf_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "ps1uQhazKCNd",
        "outputId": "c7513b68-c8c1-4a9a-bc82-f8c4d827cf91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Test Accuracy on Balanced Dataset: 96.25%\n"
          ]
        }
      ]
    }
  ]
}